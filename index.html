
<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>Mastering Diverse Domains through World Models</title>
<meta name="description" content="Abstract">
<link rel="stylesheet" href="/css/style.css">
<link rel="canonical" href="https://danijar.com/project/dreamerv3/">
</head>
<body>
<header class="wrapper">
<a class="logo" href="/">
  
  <img src="/asset/face.jpg">
  
  <div>
    <span class="title">Danijar Hafner</span>
    <span class="slogan">Artificial Intelligence Researcher</span>
  </div>
</a>
<nav>
<a href="#research">Research</a>
<a href="#featured-media">Media</a>
<a href="#highlighted-work">Papers</a>
<a href="#short-biography">Bio</a>
<!-- <a target="_blank" href="/material/danijar-hafner-resume.pdf">CV</a> -->
<!-- <a href="/research">Research</a> -->
<!-- <a href="/mentoring">Mentoring</a> -->
<!-- <a href="/resources">Resources</a> -->
</nav>
</header>
<main>
<article class="project">

<div class="cover">
<div class="wrapper">

<h1>Mastering Diverse Domains through World Models</h1>


<p class="authors">

<span class="author"><a target="_blank" href="https://danijar.com/">Danijar Hafner</a></span> <span class="author">Jurgis Pasukonis</span> <span class="author"><a target="_blank" href="https://jimmylba.github.io/">Jimmy Ba</a></span> <span class="author"><a target="_blank" href="https://contrastiveconvergence.net/~timothylillicrap/index.php">Timothy Lillicrap</a></span>

</p>



<p class="venues">

Preprint
</p>



<div class="image"><img src="https://danijar.com/asset/dreamerv3/header.gif" /></div>



<p class="buttons">

<a href="https://arxiv.org/pdf/2301.04104v1.pdf" target="_blank">Paper</a>

<a href="https://twitter.com/danijarh/status/1613161946223677441" target="_blank">Twitter</a>

<a href="https://github.com/danijar/dreamerv3" target="_blank">Code</a>

</p>


</div>
</div>

<div class="content wrapper">
<h2 id="abstract">Abstract</h2>

<p>General intelligence requires solving tasks across many domains. Current
reinforcement learning algorithms carry this potential but are held back by the
resources and knowledge required to tune them for new tasks. We present
DreamerV3, a general and scalable algorithm based on world models that
outperforms previous approaches across a wide range of domains with fixed
hyperparameters. These domains include continuous and discrete actions, visual
and low-dimensional inputs, 2D and 3D worlds, different data budgets, reward
frequencies, and reward scales. We observe favorable scaling properties of
DreamerV3, with larger models directly translating to higher data-efficiency
and final performance. Applied out of the box, DreamerV3 is the first algorithm
to collect diamonds in Minecraft from scratch without human data or curricula,
a long-standing challenge in artificial intelligence. Our general algorithm
makes reinforcement learning broadly applicable and allows scaling to hard
decision making problems.</p>

<h2 id="minecraft">Minecraft</h2>

<p>DreamerV3 is the first algorithm that collects diamonds in Minecraft without
human demonstrations or manually-crafted curricula, which poses a big
exploration challenge. The video shows the first diamond that it collects,
which happens at 30M environment steps or 17 days of playtime.</p>

<video controls="" muted="" style="width: 100%; border-radius: .25em">
<source src="/asset/dreamerv3/diamond.mp4" />
</video>

<p>Below, we show uncut videos of runs during which DreamerV3 collected diamonds.
We find that it succeeds across many starting conditions, which requires
searching the world for trees, swimming across lakes, and traversing mountains.
Note that a reward is provided only for the first diamond per episode, so the
agent is not incentiviced to pick up additional diamonds.</p>

<div class="videos">
<video controls="" muted="" autoplay="" loop=""><source src="https://user-images.githubusercontent.com/2111293/212325353-fb56ff5b-50a3-4a32-a854-35c6d8cbb490.mp4" /></video>
<video controls="" muted="" autoplay="" loop=""><source src="https://user-images.githubusercontent.com/2111293/212325324-c3eba6e8-6744-404f-8f8c-c8838e244627.mp4" /></video>
<video controls="" muted="" autoplay="" loop=""><source src="https://user-images.githubusercontent.com/2111293/212325328-64038edf-5955-487a-878b-79fb6aaf081b.mp4" /></video>
<video controls="" muted="" autoplay="" loop=""><source src="https://user-images.githubusercontent.com/2111293/212325331-8f0e08d8-805a-4fd1-8778-50bf89b1d172.mp4" /></video>
<video controls="" muted="" autoplay="" loop=""><source src="https://user-images.githubusercontent.com/2111293/212325333-7f2c0e5f-f862-45f5-8399-93aa2d94f2fb.mp4" /></video>
<video controls="" muted="" autoplay="" loop=""><source src="https://user-images.githubusercontent.com/2111293/212325334-5a44904c-4e6b-4ffe-befe-a2b99c1f5279.mp4" /></video>
<video controls="" muted="" autoplay="" loop=""><source src="https://user-images.githubusercontent.com/2111293/212325338-2c8e22a9-e3e1-4099-a015-544936583922.mp4" /></video>
<video controls="" muted="" autoplay="" loop=""><source src="https://user-images.githubusercontent.com/2111293/212325340-4d580209-6013-4fbd-aa52-e7bd3588c229.mp4" /></video>
<video controls="" muted="" autoplay="" loop=""><source src="https://user-images.githubusercontent.com/2111293/212325343-cb0a71ba-b8a0-4c81-a5a8-0b7a738b6117.mp4" /></video>
<video controls="" muted="" autoplay="" loop=""><source src="https://user-images.githubusercontent.com/2111293/212325346-1dadce21-a44e-4dfa-bc0b-72d8edca01d7.mp4" /></video>
<video controls="" muted="" autoplay="" loop=""><source src="https://user-images.githubusercontent.com/2111293/212325349-aad730cc-12dd-4f63-a0c2-7b70706b254a.mp4" /></video>
<video controls="" muted="" autoplay="" loop=""><source src="https://user-images.githubusercontent.com/2111293/212325327-93ca12d1-f268-477a-b396-337db213372d.mp4" /></video>
</div>
<style>
.videos { display: flex; flex-wrap: wrap; align-content: space-between; gap: .5em; }
.videos video { flex: 1; width: 23%; border-radius: .25em; }
.restart { display: inline-block; padding: .55em 1em .45em; border-radius: .25em; background: #ddd; cursor: pointer; }
.restart:hover { background: #eee; }
.restart:active { background: #ccc; }
</style>

<script defer="">
function restartVideos() {
  document.querySelectorAll('.videos video').forEach((video) => {
    video.pause()
    video.currentTime = 0
    video.play()
  })
}
</script>

<p style="text-align: center">
<span class="restart" onclick="restartVideos()">Restart Videos</span>
</p>

<h2 id="benchmarks">Benchmarks</h2>

<p>DreamerV3 masters a wide range of domains with a fixed set of hyperparameters,
outperforming specialized methods. Removing the need for tuning reduces the
amount of expert knowledge and computational resources needed to apply
reinforcement learning.</p>

<p style="text-align: center">
<img style="width: 78%" src="/asset/dreamerv3/benchmark.png" />
</p>

<h2 id="scaling">Scaling</h2>

<p>Due to its robustness, DreamerV3 shows favorable scaling properties. Notably,
using larger models consistently increases not only its final performance but
also its data-efficiency. Increasing the number of gradient steps further
increases data efficiency.</p>

<p><img style="width: 100%" src="/asset/dreamerv3/scaling.png" /></p>

<h2 id="data-efficiency">Data Efficiency</h2>

<p>On a set of DMLab tasks, DreamerV3 exceeds IMPALA while using over 130 times
fewer environment steps. This demonstrates that the peak performance of
DreamerV3 exceeds model-free algorithms, while reducing data requirements by
two orders of magnitude.</p>

<div class="videos dmlab">
<video controls="" muted="" autoplay="" loop=""><source src="https://user-images.githubusercontent.com/2111293/212435069-0845fe09-b3d8-4518-9172-daaac5092b2d.mp4" /></video>
<video controls="" muted="" autoplay="" loop=""><source src="https://user-images.githubusercontent.com/2111293/212435059-6ff4d419-abf6-49ae-890b-210c29a7d470.mp4" /></video>
<video controls="" muted="" autoplay="" loop=""><source src="https://user-images.githubusercontent.com/2111293/212435049-5d66a543-8dba-42ff-83fe-50774e6c8cda.mp4" /></video>
<video controls="" muted="" autoplay="" loop=""><source src="https://user-images.githubusercontent.com/2111293/212435043-419af193-9502-4d1b-8417-16358653a156.mp4" /></video>
</div>
<script defer="">
document.querySelectorAll('.videos.dmlab video').forEach((video) => {
  video.playbackRate = 0.5
})
</script>

<!-- <img style="width: 100%" src="/asset/dreamerv3/dmlab.png"> -->
<p style="text-align: center">
<img style="width: 40%" src="/asset/dreamerv3/eff.png" />
</p>

<h2 id="media-coverage">Media Coverage</h2>

<ul>
  <li><a href="https://jack-clark.net/">Import AI</a></li>
  <li><a href="https://www.marktechpost.com/2023/01/18/can-reinforcement-learning-learn-everything/">MarkTechPost</a></li>
  <li><a href="https://analyticsindiamag.com/deepmind-unleashes-dreamerv3-a-multi-domain-world-model">Analytics India Mag</a></li>
  <li><a href="https://www.youtube.com/watch?v=vfpZu0R1s1Y">Edan Meyer YouTube</a></li>
  <li><a href="https://www.infoq.com/news/2023/01/deepmind-dreamer-minecraft/">InfoQ</a></li>
  <li><a href="https://podcasts.apple.com/us/podcast/mastering-diverse-domains-through-world-models/id1577699357?i=1000601234926">Papers Read on AI Podcast</a></li>
</ul>

</div>

</article>

<script>
document.querySelector('body').onload = function() {
  console.log('SCROLL', window.scrollY);
  if (window.scrollY > 10) return;
  const element = document.querySelector('.cover')
  const pos = element.getBoundingClientRect().top + window.scrollY
  window.scroll({top: pos, behavior: 'smooth'})
}
</script>

</main>

<footer></footer>
<script>
window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
ga('create', 'UA-78082517-1', 'auto');
ga('send', 'pageview');
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>
<script async src='/scripts.js'></script>
</body>
</html>
